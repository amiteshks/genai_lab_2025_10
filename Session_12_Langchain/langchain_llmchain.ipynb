{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e6294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/amiteshsinha/Training/10_2025_genai_lab/.venv/lib/python3.13/site-packages (1.1.3)\n",
      "Requirement already satisfied: openai in /Users/amiteshsinha/Training/10_2025_genai_lab/.venv/lib/python3.13/site-packages (2.11.0)\n",
      "Requirement already satisfied: langchain-core in /Users/amiteshsinha/Training/10_2025_genai_lab/.venv/lib/python3.13/site-packages (1.1.3)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement langchain-openailangchain-community (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for langchain-openailangchain-community\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain openai langchain-core langchain-openailangchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18eabf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval-Augmented Generation (RAG) is a framework that retrieves relevant external documents and conditions a language model’s generation on them to produce more accurate, fact-based answers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# --- Load API Key ---\n",
    "load_dotenv(override=True, dotenv_path=\"../.env\")\n",
    "my_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Choose the LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\",\n",
    "    openai_api_key=my_api_key\n",
    ")\n",
    "\n",
    "# Create a prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=\"You are an AI assistant. Respond to this concept in one line: {concept}\",\n",
    "    input_variables=[\"concept\"],\n",
    ")\n",
    "\n",
    "# Build the chain (modern runnable syntax)\n",
    "chain = prompt | llm\n",
    "\n",
    "# Run the chain\n",
    "response = chain.invoke(\n",
    "    {\"concept\": \"What is Retrieval Augmented Generation?\"}\n",
    ")\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e91ed86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval-Augmented Generation (RAG) combines a retriever and a generator to fetch relevant documents and condition the model’s outputs on that external evidence.\n"
     ]
    }
   ],
   "source": [
    "# Build the chain\n",
    "#LCEL - LangChain Expression Language\n",
    "chain2_for_agentA = prompt | llm \n",
    "\n",
    "# Run the chain\n",
    "response2 = chain2_for_agentA.invoke({\"concept\": \"Retrieval Augmented Generation\"})\n",
    "print(response2.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
